{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cubic-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据打印出的文件路径，将文件读取进内存\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "train_data = pd.read_csv('./train.csv/train.csv')\n",
    "test_data = pd.read_csv('./test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gothic-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features=pd.concat((train_data.loc[:,train_data.columns!='Sold Price'],test_data.iloc[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wired-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有缺失的值替换为相应特征的平均值。通过将特征重新缩放到零均值和单位方差来标准化数据\n",
    "numeric_features=all_features.dtypes[all_features.dtypes!='object'].index\n",
    "all_features[numeric_features]=all_features[numeric_features].apply(\n",
    "    lambda x:(x-x.mean())/(x.std()))\n",
    "all_features[numeric_features]=all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "academic-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = all_features[numeric_features[1:]] # 原本第一列是Id，去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "located-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从pandas格式中提取NumPy格式，并将其转换为张量表示\n",
    "n_train=train_data.shape[0]\n",
    "train_features=torch.tensor(all_features[:n_train].values,dtype=torch.float32,device=\"cuda:0\")\n",
    "test_features=torch.tensor(all_features[n_train:].values,dtype=torch.float32,device=\"cuda:0\")\n",
    "# 注意课上数据的标签列为SalePrice，与比赛用的标签列名不同\n",
    "train_labels=torch.tensor(train_data['Sold Price'].values.reshape(-1,1),dtype=torch.float32,device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "derived-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.MSELoss()\n",
    "in_features=train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dietary-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    net=nn.Sequential(nn.Linear(in_features,256),nn.ReLU(),nn.Linear(256,64),nn.ReLU(),nn.Linear(64,1))\n",
    "    net.cuda();\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "recreational-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net,features,labels):\n",
    "    clipped_preds=torch.clamp(net(features),1,float('inf'))\n",
    "    rmse=torch.sqrt(loss(torch.log(clipped_preds),torch.log(labels)))\n",
    "    return rmse.item()\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "binary-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined in file: ./chapter_linear-networks/linear-regression-concise.md\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "upset-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们的训练函数将借助Adam优化器\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    # 注意kaggle环境中没有安装d2l，故用到的地方需要手动定义\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,\n",
    "                                 weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "least-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "looking-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回训练和验证误差的平均值\n",
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n",
    "           batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net()\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        # 删去利用d2l画图的代码\n",
    "        print(f'fold {i + 1}, train log rmse {float(train_ls[-1]):f}, '\n",
    "              f'valid log rmse {float(valid_ls[-1]):f}')\n",
    "    return train_l_sum / k, valid_l_sum / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ethical-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型选择\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
    "                          weight_decay, batch_size)\n",
    "print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n",
    "      f'平均验证log rmse: {float(valid_l):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train log rmse 1.229216\n"
     ]
    }
   ],
   "source": [
    "def train_and_pred(train_features, test_feature, train_labels, test_data,\n",
    "                   num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net()\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None,\n",
    "                        num_epochs, lr, weight_decay, batch_size)\n",
    "    # 删去利用d2l画图的代码\n",
    "    print(f'train log rmse {float(train_ls[-1]):f}')\n",
    "    preds = net(test_features).cpu().detach().numpy()\n",
    "    # 不出所料，列名需要做替换\n",
    "    test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    # 最后返回一下提交的结果，以便查看\n",
    "    return submission\n",
    "\n",
    "submission = train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "               num_epochs, lr, weight_decay, batch_size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b30b94cf5687cba103eeea663ce374a07d5aa9e910f4de9d7ea9ef055a12b030"
  },
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
