{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unable-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "raised-bench",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2755e-39, 1.0561e-38, 9.6429e-39],\n",
       "        [9.2756e-39, 9.2755e-39, 4.2246e-39],\n",
       "        [1.0286e-38, 1.0653e-38, 1.0194e-38],\n",
       "        [8.4490e-39, 1.0469e-38, 9.3674e-39],\n",
       "        [9.9184e-39, 8.7245e-39, 9.2755e-39]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.empty(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "handed-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9981, 0.3021, 0.7690],\n",
       "        [0.2581, 0.4755, 0.5394],\n",
       "        [0.5954, 0.5953, 0.5767],\n",
       "        [0.3679, 0.0961, 0.1265],\n",
       "        [0.7460, 0.9222, 0.3804]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "color-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9217,  0.8713,  1.1880],\n",
       "        [ 0.4579, -0.5280,  0.2641],\n",
       "        [-1.4634,  1.0164,  1.4280],\n",
       "        [-0.6122, -1.9241, -1.4339],\n",
       "        [-0.1918,  0.9069, -0.9524]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "opponent-crazy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caring-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([5, 3]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.zeros(5,3,dtype=torch.float32)\n",
    "x,x.size(),x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "turkish-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]], dtype=torch.float64),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.new_ones(2,4,dtype=torch.double)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "heated-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5084, -0.1973, -0.5656, -0.3186],\n",
       "         [ 1.2805,  0.4049, -0.5291,  0.6805]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.randn_like(x,dtype=torch.float)\n",
    "y,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "severe-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3628,  1.5076,  2.3950],\n",
       "         [ 1.5625, -0.5239, -1.6277],\n",
       "         [-0.2301, -1.3092, -0.2275],\n",
       "         [-0.7978, -0.5275, -0.2953],\n",
       "         [ 1.3049,  1.1254, -0.5533]]),\n",
       " tensor([[-0.8024, -1.5781,  0.5847],\n",
       "         [ 0.0261, -0.0579, -0.2084],\n",
       "         [-0.4316,  0.9030,  0.7422],\n",
       "         [ 0.9184, -1.5516, -0.3537],\n",
       "         [-0.0712, -0.3026, -0.5620]]),\n",
       " torch.Size([5, 3]),\n",
       " torch.Size([5, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.randn(5,3)\n",
    "x=torch.randn(5,3)\n",
    "x,y,x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "russian-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1653, -0.0705,  2.9797],\n",
       "         [ 1.5886, -0.5818, -1.8361],\n",
       "         [-0.6617, -0.4062,  0.5147],\n",
       "         [ 0.1205, -2.0791, -0.6490],\n",
       "         [ 1.2337,  0.8228, -1.1153]]),\n",
       " tensor([[-1.1653, -0.0705,  2.9797],\n",
       "         [ 1.5886, -0.5818, -1.8361],\n",
       "         [-0.6617, -0.4062,  0.5147],\n",
       "         [ 0.1205, -2.0791, -0.6490],\n",
       "         [ 1.2337,  0.8228, -1.1153]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y,torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "defined-tomato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1653, -0.0705,  2.9797],\n",
       "         [ 1.5886, -0.5818, -1.8361],\n",
       "         [-0.6617, -0.4062,  0.5147],\n",
       "         [ 0.1205, -2.0791, -0.6490],\n",
       "         [ 1.2337,  0.8228, -1.1153]]),\n",
       " tensor([[-0.3628,  1.5076,  2.3950],\n",
       "         [ 1.5625, -0.5239, -1.6277],\n",
       "         [-0.2301, -1.3092, -0.2275],\n",
       "         [-0.7978, -0.5275, -0.2953],\n",
       "         [ 1.3049,  1.1254, -0.5533]]),\n",
       " tensor([[-0.8024, -1.5781,  0.5847],\n",
       "         [ 0.0261, -0.0579, -0.2084],\n",
       "         [-0.4316,  0.9030,  0.7422],\n",
       "         [ 0.9184, -1.5516, -0.3537],\n",
       "         [-0.0712, -0.3026, -0.5620]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "result,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "steady-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3628,  1.5076,  2.3950],\n",
      "        [ 1.5625, -0.5239, -1.6277],\n",
      "        [-0.2301, -1.3092, -0.2275],\n",
      "        [-0.7978, -0.5275, -0.2953],\n",
      "        [ 1.3049,  1.1254, -0.5533]]) tensor([[-1.1653, -0.0705,  2.9797],\n",
      "        [ 1.5886, -0.5818, -1.8361],\n",
      "        [-0.6617, -0.4062,  0.5147],\n",
      "        [ 0.1205, -2.0791, -0.6490],\n",
      "        [ 1.2337,  0.8228, -1.1153]])\n",
      "tensor([[-1.5281,  1.4371,  5.3747],\n",
      "        [ 3.1511, -1.1057, -3.4638],\n",
      "        [-0.8918, -1.7154,  0.2871],\n",
      "        [-0.6773, -2.6065, -0.9442],\n",
      "        [ 2.5386,  1.9481, -1.6687]]) tensor([ 1.4371, -1.1057, -1.7154, -2.6065,  1.9481])\n"
     ]
    }
   ],
   "source": [
    "print(x,y)\n",
    "y.add_(x)\n",
    "print(y,y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fuzzy-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "b=a.numpy()\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "noble-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "successful-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 2., 2., 2.]),\n",
       " tensor([2., 2., 2., 2., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "acceptable-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.ones(2,2,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "heard-graduation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3.],\n",
       "         [3., 3.]], grad_fn=<AddBackward0>),\n",
       " <AddBackward0 at 0x20d44124730>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x+2\n",
    "y,y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "elegant-challenge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5.],\n",
       "         [2., 3., 4., 5., 6.]], requires_grad=True),\n",
       " tensor(3.5000, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=torch.tensor([[1,2,3,4,5],[2,3,4,5,6]],dtype=torch.float32,requires_grad=True)\n",
    "aa,aa.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "informational-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "10\n",
      "torch.Size([6, 1, 5, 5]) torch.Size([6]) torch.Size([16, 6, 5, 5]) torch.Size([16])\n",
      "tensor([[ 0.1538,  0.0388,  0.0088, -0.1364, -0.0745,  0.0527, -0.1482, -0.0273,\n",
      "          0.0555, -0.0899]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 汉字均为我个人理解，英文为原文标注。\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 继承原有模型\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        # 定义了两个卷积层\n",
    "        # 第一层是输入1维的（说明是单通道，灰色的图片）图片，输出6维的的卷积层（说明用到了6个卷积核，而每个卷积核是5*5的）。\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 第一层是输入1维的（说明是单通道，灰色的图片）图片，输出6维的的卷积层（说明用到了6个卷积核，而每个卷积核是5*5的）。\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # 定义了三个全连接层，即fc1与conv2相连，将16张5*5的卷积网络一维化，并输出120个节点。\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # 将120个节点转化为84个。\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 将84个节点输出为10个，即有10个分类结果。\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        # 用relu激活函数作为一个池化层，池化的窗口大小是2*2，这个也与上文的16*5*5的计算结果相符（一开始我没弄懂为什么fc1的输入点数是16*5*5,后来发现，这个例子是建立在lenet5上的）。\n",
    "        # 这句整体的意思是，先用conv1卷积，然后激活，激活的窗口是2*2。\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        # 作用同上，然后有个需要注意的地方是在窗口是正方形的时候，2的写法等同于（2，2）。\n",
    "        # 这句整体的意思是，先用conv2卷积，然后激活，激活的窗口是2*2。\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # 这句整体的意思是，调用下面的定义好的查看特征数量的函数，将我们高维的向量转化为一维。\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # 用一下全连接层fc1，然后做一个激活。\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 用一下全连接层fc2，然后做一个激活。\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 用一下全连接层fc3。\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        # 承接上文的引用，这里需要注意的是，由于pytorch只接受图片集的输入方式（原文的单词是batch）,所以第一个代表个数的维度被忽略。\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "\"\"\"\n",
    "Net(\n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 现在我们已经构建好模型了，但是还没有开始用bp呢，如果你对前面的内容有一些印象的话，你就会想起来不需要我们自己去搭建，我们只需要用某一个属性就可以了，autograd。\n",
    "\n",
    "# 现在我们需要来看一看我们的模型，下列语句可以帮助你看一下这个模型的一些具体情况。\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size(),params[1].size(),params[2].size(),params[3].size())  # conv1's .weight\n",
    "\n",
    "\"\"\"\n",
    "10\n",
    "torch.Size([6, 1, 5, 5])\n",
    "\"\"\"\n",
    "\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "\"\"\"\n",
    "tensor([[ 0.0114,  0.0476, -0.0647,  0.0381,  0.0088, -0.1024, -0.0354,  0.0220,\n",
    "         -0.0471,  0.0586]], grad_fn=<AddmmBackward>)\n",
    "\"\"\"\n",
    "\n",
    "#最后让我们清空缓存，准备下一阶段的任务。\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b30b94cf5687cba103eeea663ce374a07d5aa9e910f4de9d7ea9ef055a12b030"
  },
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
